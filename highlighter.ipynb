{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install newspaper3k\n",
    "#!pip install bert-extractive-summarizer\n",
    "#!pip install spacy\n",
    "#!pip install transformers==2.2.0\n",
    "#!pip install torch\n",
    "#!pip install pandas\n",
    "#!pip install -r requirements.txt\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from newspaper import Article\n",
    "from summarizer import Summarizer\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install --upgrade tensorflow==2.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and sparse the webpage\n",
    "\n",
    "#url = \"https://www.channelnewsasia.com/news/singapore/coronavirus-covid-19-chan-chun-sing-food-supply-12545326\"\n",
    "#url = \"https://www.channelnewsasia.com/news/asia/malaysia-bars-citizens-overseas-foreigners-entering-covid19-12543454\"\n",
    "#url = \"https://www.channelnewsasia.com/news/sport/valencia-say-35per-cent-of-squad--staff-tested-positive-for-coronavirus-12545632\"\n",
    "\n",
    "# article = Article(url)\n",
    "# article.download()\n",
    "# article.parse()\n",
    "# article.nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1 get full articles\n",
    "\n",
    "def getArticle(urls):\n",
    "    global title\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "    full = article.text\n",
    "    title = article.title\n",
    "    return full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2: extractive summary\n",
    "\n",
    "def extSumm(full):\n",
    "    orgi = full\n",
    "    model = Summarizer( model ='distilbert-base-uncased') # can adjust parameters\n",
    "    summa = model(orgi, min_length=60) # can adjust parameters\n",
    "    return summa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trying different model \n",
    "# models = ['bert-base-uncased','xlnet-base-cased', 'distilbert-base-uncased','albert-base-v1']\n",
    "\n",
    "# for mod in models:\n",
    "#     last_time = datetime.now()\n",
    "#     bert_test = full\n",
    "#     model = Summarizer(model = mod) # can adjust parameters\n",
    "#     summa = model(bert_test, min_length=60)\n",
    "#     past_time = datetime.now() - last_time\n",
    "#     print()\n",
    "#     print( mod, \": Completed in: {}\".format(past_time))\n",
    "#     print(\"Length of Summarised article: %d words\" %len(summa))\n",
    "#     print()\n",
    "#     #print(summa)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Length of original article: %d words\" %len(full))\n",
    "# print(\"Length of summarised article: %d words\" %len(summa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3 cleaning up text\n",
    "\n",
    "def cleanup(textbody):\n",
    "    \n",
    "    main_list =[]\n",
    "    for word in range(len(textbody)):\n",
    "        sentence = textbody[word].split(\"\\n\")\n",
    "        main_list.append(sentence)\n",
    "\n",
    "    main_list = [item for items in main_list for item in items] \n",
    "    \n",
    "        \n",
    "    textbody = main_list\n",
    "    return textbody\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4 tokenise text \n",
    "\n",
    "def tokenise(text):\n",
    "    orgi = sent_tokenize(text)\n",
    "    orgi = cleanup(orgi)\n",
    "    return orgi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of su\n",
    "\n",
    "# orgiD= orgi\n",
    "# summD= summ\n",
    "# print(\"No of sentences in original article: %d \" %len(orgiD))\n",
    "# print(\"No of sentences in summarised article: %d \" %len(summD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5 highlighting tool for summaried sentenses that are in original article\n",
    "  \n",
    "def highlight(List1, List2): \n",
    "    check = False\n",
    "    global full_list\n",
    "    full_list=[]\n",
    "  \n",
    "    # Iterate in the 1st list \n",
    "    for m in List1: \n",
    "        full_list.append(m)\n",
    "  \n",
    "        # Iterate in the 2nd list \n",
    "        for n in List2: \n",
    "    \n",
    "            # if there is a match\n",
    "            if m == n: \n",
    "                check = True\n",
    "                full_list.pop()\n",
    "                full_list.append(\"<hl>\"+ m)           \n",
    "                  \n",
    "    return full_list\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 clean save \n",
    "\n",
    "\n",
    "# def cleanSave(full_list):\n",
    "    \n",
    "#     article = Article(url)\n",
    "    \n",
    "#     summ_list = []\n",
    "#     for things in full_list:\n",
    "#         if len(things) >60:\n",
    "#             summ_list.append(things)\n",
    "    \n",
    "#     #title = article.title\n",
    "#     df = pd.DataFrame(summ_list, columns = [title])\n",
    "#     print(article.title)\n",
    "    \n",
    "#     df.to_csv (r'cna_news.csv', index = False, header=True)\n",
    "\n",
    "#     return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 clean and save\n",
    "\n",
    "\n",
    "def cleanSave(full_list):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    \n",
    "    summ_list = []\n",
    "    for things in full_list:\n",
    "        if len(things) >60:\n",
    "            summ_list.append(things)\n",
    "    \n",
    "    #title = article.title\n",
    "    df = pd.DataFrame(summ_list, columns = [title])\n",
    "\n",
    "    path = r\".\\data\"\n",
    "    name = \"cna_news.csv\"\n",
    "    fileloc = os.path.join(path, name)\n",
    "    df.to_csv (fileloc, index = False, header=True)\n",
    "    print(fileloc)\n",
    "    \n",
    "    return fileloc\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inputHere(url):\n",
    "    \n",
    "    full = getArticle(url)\n",
    "    summ = extSumm(full)\n",
    "    \n",
    "    list1 = tokenise(full)\n",
    "    list2 = tokenise(summ)\n",
    "    \n",
    "    \n",
    "    fullart= highlight(list1, list2)\n",
    "    df = cleanSave(fullart)\n",
    "    \n",
    "    return df \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\cna_news.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.\\\\data\\\\cna_news.csv'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputHere(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
